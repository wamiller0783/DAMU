{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import UnicodeDammit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define variables for the parent website plus the URL for the first page of any search results\n",
    "parent_link = 'https://www.hindawi.com'\n",
    "search_link_modifier = '/search/all/cellular+aging/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(page_link):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        page_line (str): any valid URL\n",
    "        \n",
    "    Returns:\n",
    "        page_content (obj): BeautifulSoup parsable webcontent associated with the input URL \n",
    "    \n",
    "    To-do:\n",
    "        Add error handling based on page_response\n",
    "    \"\"\"\n",
    "    page_response = requests.get(page_link, timeout=5)\n",
    "    page_content = BeautifulSoup(page_response.content, \"html.parser\")\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_from_parent(parent_content, search_substring):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        parent_content (obj): BeautifulSoup parsed html\n",
    "            \n",
    "        search_substring (str): string to search for within link URL\n",
    "   \n",
    "    Returns:\n",
    "        list_links (list): List of links meeting search criteria\n",
    "    \"\"\" \n",
    "    list_links = []\n",
    "    for link in parent_content.findAll('a', href=re.compile(search_substring)):\n",
    "        list_links.append(link.get('href'))\n",
    "    return list_links\n",
    "            \n",
    "# def link_next_parent(parent_content, journal_name):\n",
    "#     if journal_name == 'hindawi':\n",
    "#         for link in parent_content.findAll('a', href=re.compile('search/')):\n",
    "#             print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_search_links(parent_link, search_link_modifier, next_search_modifier, max_count = 1000, **kws):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parent_link (str): \n",
    "            URL of parent site ('https://www.hindawi.com')\n",
    "        \n",
    "        search_link_modifier (str): \n",
    "            string to add to parent URL that links to the first search term\n",
    "            ('/search/all/biological+aging/' within 'https://www.hindawi.com/search/all/biological+aging/')\n",
    "    \n",
    "        next_search_modifier (str): \n",
    "            string (plus optional regex) within a URL that signifies a link to the next\n",
    "            page of search results ('search/' within 'https://www.hindawi.com/search/all/biological+aging/2/')\n",
    "            \n",
    "        max_count (int):\n",
    "            maximum number of links to get from search to prevent the indefinite retrieval.\n",
    "    \n",
    "    Returns:\n",
    "        list_links (list): \n",
    "            All links to all pages of search results within the parent site which correspond to the search term\n",
    "    \"\"\"\n",
    "    list_links = [search_link_modifier]\n",
    "    e = 0\n",
    "    i = 0\n",
    "    while (e == 0) and (i < max_count):\n",
    "        search_content = fetch_page(parent_link + search_link_modifier)\n",
    "        \n",
    "        next_search_link = links_from_parent(search_content, next_search_modifier)\n",
    "        if next_search_link[-1] not in list_links:\n",
    "            list_links.append(next_search_link[-1])\n",
    "            search_link_modifier = next_search_link[-1]\n",
    "        else:\n",
    "            e = 1\n",
    "        i += 1\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_journal_links(parent_link, search_link_list, journal_link_identifier):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parent_link (str): \n",
    "            URL of parent site ('https://www.hindawi.com')\n",
    "        \n",
    "        search_link_list (list): \n",
    "            list of strings string to add to parent URL to get search pages\n",
    "            (['/search/all/biological+aging/', '/search/all/biological+aging/2/'] \n",
    "            within 'https://www.hindawi.com/search/all/biological+aging/' and \n",
    "            'https://www.hindawi.com/search/all/biological+aging/2/, respectively.\n",
    "\n",
    "    \n",
    "        journal_link_identifier (str): \n",
    "            string (plus optional regex) within a URL that signifies a link to a journal\n",
    "            ('journals/[a-z]' within 'https://www.hindawi.com/journals/[string starting with any letter]')\n",
    "    \n",
    "    Returns:\n",
    "        list_links (list): \n",
    "            All links to all journals within the parent site which correspond to the search term\n",
    "    \"\"\"\n",
    "    list_links = []\n",
    "    for search_link_modifier in tqdm(search_link_list):\n",
    "        search_content = fetch_page(parent_link + search_link_modifier)\n",
    "        page_links = links_from_parent(search_content, journal_link_identifier)\n",
    "        list_links = list_links + page_links\n",
    "    return list_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_journal_text(parent_link, journal_link_modifier, text_container, text_identifier):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parent_link (str): \n",
    "            URL of parent site ('https://www.hindawi.com')\n",
    "    \n",
    "        journal_link_modifier (str):\n",
    "            string within a URL that signifies a link to a specific journal article\n",
    "            ('/journals/omcl/2012/919832/' within 'https://www.hindawi.com/journals/omcl/2012/919832/')\n",
    "    \n",
    "        text_container (str):\n",
    "            string that determines what kind of html tag contains the text to scrape. \n",
    "            (most commonly 'div' but may be 'p' or some other tag)\n",
    "        \n",
    "        text_identifier (dict):\n",
    "            dictionary that defines the properties of the text container from which to scrape the text.\n",
    "            ({'class': 'article_type'} or {'id': 'article_text'})\n",
    "            \n",
    "    Returns:\n",
    "        unicode_text (str):\n",
    "            The text of the journal in unicode.\n",
    "    \"\"\"\n",
    "    \n",
    "    page_content = fetch_page(parent_link + journal_link_modifier)\n",
    "    try:\n",
    "        journal_text = page_content.find(text_container, text_identifier).parent.get_text(' ')\n",
    "    except:\n",
    "        journal_text = 'Text could not be retrieved.'\n",
    "        \n",
    "    \n",
    "    #Convert journal text to unicode and return unicode markup.\n",
    "    unicode_text = UnicodeDammit(journal_text).unicode_markup\n",
    "    \n",
    "    return unicode_text #Can be subbed with journal_text if unicode is not preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_journal_text(parent_link, all_journal_modifiers, text_container, text_identifier):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        parent_link (str): \n",
    "            URL of parent site ('https://www.hindawi.com')\n",
    "    \n",
    "        all_journal_modifiers (list):\n",
    "            string within a URL that signifies a link to a specific journal article\n",
    "            ('/journals/omcl/2012/919832/' within 'https://www.hindawi.com/journals/omcl/2012/919832/')\n",
    "    \n",
    "        text_container (str):\n",
    "            string that determines what kind of html tag contains the text to scrape. \n",
    "            (most commonly 'div' but may be 'p' or some other tag)\n",
    "        \n",
    "        text_identifier (dict):\n",
    "            dictionary that defines the properties of the text container from which to scrape the text.\n",
    "            ({'class': 'article_type'} or {'id': 'article_text'})\n",
    "            \n",
    "    Returns:\n",
    "        journal_text (dict):\n",
    "            A dictionary of the text for each journal passed in list\n",
    "    \"\"\"\n",
    "    journal_text = {}\n",
    "    for journal_link in tqdm(all_journal_modifiers):\n",
    "        journal_text[journal_link] = get_journal_text(parent_link, journal_link, text_container, text_identifier)\n",
    "    \n",
    "    return journal_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_journal_text(filepath, filename, journal_text_dict, \n",
    "                      method = 'a+', encoding = 'utf-8', **kwargs):\n",
    "    textfile = open(filepath + filename, method, encoding=encoding)\n",
    "    dividing_text = '\\n\\n\\n\\n\\n'\n",
    "    for text in tqdm(journal_text_dict.values()):\n",
    "        textfile.write(text + dividing_text)\n",
    "    textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_links = get_all_search_links(parent_link, search_link_modifier, 'search/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 629/629 [05:25<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "journal_links = get_all_journal_links(parent_link, search_links, 'journals/[a-z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15702/15702 [2:57:16<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "journals = get_all_journal_text(parent_link, journal_links, 'div', {'class': 'article_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15702/15702 [00:02<00:00, 5653.43it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath = './'\n",
    "filename = 'ResearchJournals_Senescence.txt'\n",
    "save_journal_text(filepath, filename, journals, method='w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_journals = pd.DataFrame.from_dict(journals, orient='index', columns=['ArticleText'])\n",
    "# df_journals.to_csv('./ResearchJournals_Senescence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
